---
title: "Desafio Data Science"
author: "Henrique C Vieira"
date: "Junho 4, 2018"
output:
  html_document: default
  pdf_document: default
---

# Analisando os dados bank

O dado **Bank Marketing** foi obtido do repositório de datasets [https://archive.ics.uci.edu](https://archive.ics.uci.edu/ml/datasets/bank+marketing)

Link para download:
[bank.zip](https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank.zip) 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Carregando bibliotecas a serem usadas nesse projeto.

```{r load libraries, warning=FALSE}
library(dplyr, warn.conflicts=FALSE, verbose=FALSE)
library(ggplot2, warn.conflicts=FALSE, verbose=FALSE)
library(tidyr, warn.conflicts=FALSE, verbose=FALSE)
library(readr, warn.conflicts=FALSE, verbose=FALSE)
```

### Carregando o dataset bank e descrição das variáveis.
```{r load data}
dataset <- read_delim('bank/bank.csv', delim = ';')
glimpse(dataset)
```

### Alterando o tipo da coluna para o tipo correto

```{r}
dataset$job <- as.factor(dataset$job)
dataset$marital <- as.factor(dataset$marital)
dataset$education <- as.factor(dataset$education)
dataset$default <- ifelse(dataset$default == 'yes', TRUE, FALSE)
dataset$housing <- ifelse(dataset$housing == 'yes', TRUE, FALSE)
dataset$loan <- ifelse(dataset$loan == 'yes', TRUE, FALSE)
dataset$contact <- as.factor(dataset$contact)
dataset$day <- as.factor(dataset$day)
dataset$month <- as.factor(dataset$month)
dataset$campaign <- as.factor(dataset$campaign)
dataset$poutcome <- as.factor(dataset$poutcome)
dataset$y <- ifelse(dataset$y == 'yes', TRUE, FALSE)
dataset$term <- dataset$y
glimpse(dataset)
```

### Sumarização dos dados
Podemos observar abaixo, os valores de minimo, máximo, 1º, 2º (mediana) e 3º quartil e a média para dados númericos e a contagem individual para cada valor para os dados categóricos.

Podemos perceber o desbalanceamento dos dados.
```{r}
dataset %>%
  summary()
```

### Relações e gráficos

#### Número de individuos pela ocupação profissional e estado civil.
```{r}
dataset %>%
  group_by(job) %>%
  count(marital, sort = TRUE)
```

#### Número total de sucessos por campanha
```{r}
dataset %>%
  group_by(poutcome) %>% 
  filter(poutcome == "success") %>%
  count(campaign, sort = TRUE)
```

#### Número de individuos por nível escolar
```{r}
ggplot(dataset, aes(x=education)) + 
  geom_bar()
```

#### Número de individuos pela ocupação profissional
```{r}
ggplot(dataset, aes(x=job)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### Distribuição da idade
```{r}
ggplot(dataset, aes(x=age, y=..density..)) + 
  geom_histogram() +
  geom_density() + 
  geom_vline(aes(xintercept=mean(age)),
            color="blue", linetype="dashed", size=1)
```

#### Relação entre ocupação profissional e a idade
```{r}
ggplot(dataset, aes(x=job, y=age)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### Número de contratos assinados
```{r}
ggplot(dataset, aes(x=poutcome, fill=term)) +
  geom_bar()
```

#### Número de contratos assinados pela campanha e estado (sucesso, falha e outros)
```{r}
ggplot(dataset, aes(x=campaign, fill=term)) +
  geom_bar() +
  facet_grid(poutcome ~ .)
```

# Predição

Usando tecnicas de aprendizado de maquina, vamos substituir os valores 'unknown' por outros valores.

```{r}
library(rpart)
library(naivebayes)
```

### Job
```{r}
job_unknown <- dataset$job == 'unknown'
dataset_job_real <- dataset[!job_unknown,]
dataset_job_unknown <- dataset[job_unknown,]
dataset_job_real$job <- droplevels(dataset_job_real$job)
dataset_job_unknown <- dataset_job_unknown[, colnames(dataset_job_unknown) != 'job']
```

```{r}
job_model <- rpart(job ~ age+marital, dataset_job_real, method = 'class')
```

```{r}
job_pred <- predict(job_model, dataset_job_unknown, type='class')
```

```{r}
plotcp(job_model)
```

```{r}
rpart.plot::rpart.plot(job_model)
```

Put new values
```{r}
dataset$job[job_unknown] <- job_pred
dataset$job <- droplevels(dataset$job)
ggplot(dataset, aes(x=job)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Education
```{r}
education_unknown <- dataset$education == 'unknown'
dataset_education_real <- dataset[!education_unknown,]
dataset_education_unknown <- dataset[education_unknown,]
dataset_education_real$education <- droplevels(dataset_education_real$education)
dataset_education_unknown <- dataset_education_unknown[, colnames(dataset_education_unknown) != 'education']
```

```{r}
education_model <- rpart(education ~ age+marital+job, dataset_education_real, method = 'class')
```

```{r}
education_pred <- predict(education_model, dataset_education_unknown, type='class')
```

```{r}
plotcp(education_model)
```

```{r}
rpart.plot::rpart.plot(education_model)
```

Put new values
```{r}
dataset$education[education_unknown] <- education_pred
dataset$education <- droplevels(dataset$education)
ggplot(dataset, aes(x=education)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Poutcome
```{r}
poutcome_unknown <- dataset$poutcome == 'unknown'
dataset_poutcome_real <- dataset[!poutcome_unknown,]
dataset_poutcome_unknown <- dataset[poutcome_unknown,]
dataset_poutcome_real$poutcome <- droplevels(dataset_poutcome_real$poutcome)
dataset_poutcome_unknown <- dataset_poutcome_unknown[, colnames(dataset_poutcome_unknown) != 'poutcome']
```

```{r}
poutcome_model <- rpart(poutcome ~ age+marital+job+default+housing+loan+campaign, dataset_poutcome_real, method = 'class')
```

```{r}
poutcome_pred <- predict(poutcome_model, dataset_poutcome_unknown, type='class')
```

```{r}
plotcp(poutcome_model)
```

```{r}
rpart.plot::rpart.plot(poutcome_model)
```

Put new values
```{r}
dataset$poutcome[poutcome_unknown] <- poutcome_pred
dataset$poutcome <- droplevels(dataset$poutcome)
ggplot(dataset, aes(x=poutcome)) +
  geom_bar() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Predict Term

## Make two groups: train and control
```{r}
set.seed(100)
pos <- sample(1:nrow(dataset), round(nrow(dataset)*0.1, 0))
dataset_train <- dataset[-pos,]
dataset_test <- dataset[pos,]
class <- dataset_test$term
dataset_test <- dataset_test[,!colnames(dataset_test)=='term']
```

### Naive bayes

Using all categoric features
```{r}
# job
# marital
# education
# default
# housing
# loan
# contact
# day
# month
# campaign
# poutcome

m <- naive_bayes(term ~ duration +
                        job +
                        marital +
                        education +
                        default +
                        housing +
                        loan +
                        contact +
                        day +
                        month +
                        campaign +
                        poutcome, dataset_train)
```

```{r}
pred <- predict(m, dataset_test)
```

```{r}
confusion_matrix <- table(pred, class)
confusion_matrix
```

```{r}
accuracy <- (confusion_matrix[1,2] + confusion_matrix[2,2]) / sum(confusion_matrix)
recall <- confusion_matrix[2,2] / (confusion_matrix[1,1] + confusion_matrix[2,2])
precision <- confusion_matrix[2,2] / (confusion_matrix[2,1] + confusion_matrix[2,2])

accuracy
recall
precision
```

### Decision tree

```{r}
m2 <- rpart(term ~ duration +
                   # job +
                   # marital +
                   # education +
                   # default +
                   # housing +
                   # loan +
                   # contact +
                   # day +
                   # month +
                   campaign +
                   poutcome,
                   dataset_train, method = 'class')
```

```{r}
pred2	<- predict(m2,	dataset_test,	type	=	"class")
```

```{r}
confusion_matrix <- table(pred2, class)
confusion_matrix
```

```{r}
accuracy <- (confusion_matrix[1,2] + confusion_matrix[2,2]) / sum(confusion_matrix)
recall <- confusion_matrix[2,2] / (confusion_matrix[1,1] + confusion_matrix[2,2])
precision <- confusion_matrix[2,2] / (confusion_matrix[2,1] + confusion_matrix[2,2])

accuracy
recall
precision
```

```{r}
plotcp(m2)
```

```{r}
rpart.plot::rpart.plot(m2)
```

Dado este resultado obtido com Decision Tree, podemos observar que o desbalanceamento da váriavel *term* (inicialmente chamada de *y*) nos permite ter um grande sucesso em predizer quando ocorre 'No' mas erra muito ao tentar predizer o 'Yes'.

Abaixo iremos balancear este dado e vamos observar se temos uma melhora na predição.

```{r}
table(dataset$poutcome, dataset$term)
```


